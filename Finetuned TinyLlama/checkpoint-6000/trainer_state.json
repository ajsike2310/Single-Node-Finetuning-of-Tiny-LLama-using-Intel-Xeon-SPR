{
  "best_metric": 1.2526891231536865,
  "best_model_checkpoint": "tmp_tinyllama_1720769940/checkpoint-4500",
  "epoch": 0.9323284904047859,
  "eval_steps": 100,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0155388081734131,
      "grad_norm": 1.3828125,
      "learning_rate": 4.922299922299923e-05,
      "loss": 1.3206,
      "step": 100
    },
    {
      "epoch": 0.0155388081734131,
      "eval_loss": 1.307770013809204,
      "eval_ppl": 3.6979182042667436,
      "step": 100
    },
    {
      "epoch": 0.0310776163468262,
      "grad_norm": 0.7578125,
      "learning_rate": 4.844599844599845e-05,
      "loss": 1.2882,
      "step": 200
    },
    {
      "epoch": 0.0310776163468262,
      "eval_loss": 1.2905761003494263,
      "eval_ppl": 3.6348800083184467,
      "step": 200
    },
    {
      "epoch": 0.0466164245202393,
      "grad_norm": 0.81640625,
      "learning_rate": 4.766899766899767e-05,
      "loss": 1.2917,
      "step": 300
    },
    {
      "epoch": 0.0466164245202393,
      "eval_loss": 1.2808231115341187,
      "eval_ppl": 3.599601379930186,
      "step": 300
    },
    {
      "epoch": 0.0621552326936524,
      "grad_norm": 0.984375,
      "learning_rate": 4.689199689199689e-05,
      "loss": 1.2846,
      "step": 400
    },
    {
      "epoch": 0.0621552326936524,
      "eval_loss": 1.2748439311981201,
      "eval_ppl": 3.5781429300420093,
      "step": 400
    },
    {
      "epoch": 0.0776940408670655,
      "grad_norm": 1.03125,
      "learning_rate": 4.611499611499612e-05,
      "loss": 1.2736,
      "step": 500
    },
    {
      "epoch": 0.0776940408670655,
      "eval_loss": 1.2718515396118164,
      "eval_ppl": 3.5674517293508368,
      "step": 500
    },
    {
      "epoch": 0.0932328490404786,
      "grad_norm": 0.8203125,
      "learning_rate": 4.533799533799534e-05,
      "loss": 1.2726,
      "step": 600
    },
    {
      "epoch": 0.0932328490404786,
      "eval_loss": 1.2692153453826904,
      "eval_ppl": 3.558059618842219,
      "step": 600
    },
    {
      "epoch": 0.10877165721389169,
      "grad_norm": 1.03125,
      "learning_rate": 4.456099456099456e-05,
      "loss": 1.242,
      "step": 700
    },
    {
      "epoch": 0.10877165721389169,
      "eval_loss": 1.2683911323547363,
      "eval_ppl": 3.5551282279613563,
      "step": 700
    },
    {
      "epoch": 0.1243104653873048,
      "grad_norm": 1.0546875,
      "learning_rate": 4.378399378399379e-05,
      "loss": 1.2608,
      "step": 800
    },
    {
      "epoch": 0.1243104653873048,
      "eval_loss": 1.2668997049331665,
      "eval_ppl": 3.5498299642050064,
      "step": 800
    },
    {
      "epoch": 0.13984927356071788,
      "grad_norm": 1.0859375,
      "learning_rate": 4.300699300699301e-05,
      "loss": 1.2626,
      "step": 900
    },
    {
      "epoch": 0.13984927356071788,
      "eval_loss": 1.265575647354126,
      "eval_ppl": 3.545132895217705,
      "step": 900
    },
    {
      "epoch": 0.155388081734131,
      "grad_norm": 1.2578125,
      "learning_rate": 4.222999222999223e-05,
      "loss": 1.2713,
      "step": 1000
    },
    {
      "epoch": 0.155388081734131,
      "eval_loss": 1.2639797925949097,
      "eval_ppl": 3.5394798899022697,
      "step": 1000
    },
    {
      "epoch": 0.1709268899075441,
      "grad_norm": 1.09375,
      "learning_rate": 4.145299145299146e-05,
      "loss": 1.255,
      "step": 1100
    },
    {
      "epoch": 0.1709268899075441,
      "eval_loss": 1.2627449035644531,
      "eval_ppl": 3.535111722668711,
      "step": 1100
    },
    {
      "epoch": 0.1864656980809572,
      "grad_norm": 0.9765625,
      "learning_rate": 4.067599067599068e-05,
      "loss": 1.2535,
      "step": 1200
    },
    {
      "epoch": 0.1864656980809572,
      "eval_loss": 1.2630186080932617,
      "eval_ppl": 3.53607943118411,
      "step": 1200
    },
    {
      "epoch": 0.2020045062543703,
      "grad_norm": 0.85546875,
      "learning_rate": 3.98989898989899e-05,
      "loss": 1.2349,
      "step": 1300
    },
    {
      "epoch": 0.2020045062543703,
      "eval_loss": 1.2597479820251465,
      "eval_ppl": 3.5245331297273794,
      "step": 1300
    },
    {
      "epoch": 0.21754331442778338,
      "grad_norm": 2.15625,
      "learning_rate": 3.912198912198912e-05,
      "loss": 1.2707,
      "step": 1400
    },
    {
      "epoch": 0.21754331442778338,
      "eval_loss": 1.2610889673233032,
      "eval_ppl": 3.5292626472351984,
      "step": 1400
    },
    {
      "epoch": 0.23308212260119648,
      "grad_norm": 1.5,
      "learning_rate": 3.834498834498835e-05,
      "loss": 1.2498,
      "step": 1500
    },
    {
      "epoch": 0.23308212260119648,
      "eval_loss": 1.2595475912094116,
      "eval_ppl": 3.5238269164201226,
      "step": 1500
    },
    {
      "epoch": 0.2486209307746096,
      "grad_norm": 0.8359375,
      "learning_rate": 3.7567987567987566e-05,
      "loss": 1.2688,
      "step": 1600
    },
    {
      "epoch": 0.2486209307746096,
      "eval_loss": 1.2596286535263062,
      "eval_ppl": 3.524112577572324,
      "step": 1600
    },
    {
      "epoch": 0.2641597389480227,
      "grad_norm": 1.2890625,
      "learning_rate": 3.679098679098679e-05,
      "loss": 1.2621,
      "step": 1700
    },
    {
      "epoch": 0.2641597389480227,
      "eval_loss": 1.2581911087036133,
      "eval_ppl": 3.5190501473888056,
      "step": 1700
    },
    {
      "epoch": 0.27969854712143577,
      "grad_norm": 1.3046875,
      "learning_rate": 3.601398601398602e-05,
      "loss": 1.2498,
      "step": 1800
    },
    {
      "epoch": 0.27969854712143577,
      "eval_loss": 1.2601536512374878,
      "eval_ppl": 3.5259632143570276,
      "step": 1800
    },
    {
      "epoch": 0.2952373552948489,
      "grad_norm": 2.78125,
      "learning_rate": 3.523698523698524e-05,
      "loss": 1.2589,
      "step": 1900
    },
    {
      "epoch": 0.2952373552948489,
      "eval_loss": 1.2575349807739258,
      "eval_ppl": 3.516741957617828,
      "step": 1900
    },
    {
      "epoch": 0.310776163468262,
      "grad_norm": 1.21875,
      "learning_rate": 3.445998445998446e-05,
      "loss": 1.2821,
      "step": 2000
    },
    {
      "epoch": 0.310776163468262,
      "eval_loss": 1.2572630643844604,
      "eval_ppl": 3.5157858278416008,
      "step": 2000
    },
    {
      "epoch": 0.3263149716416751,
      "grad_norm": 0.96484375,
      "learning_rate": 3.368298368298368e-05,
      "loss": 1.2502,
      "step": 2100
    },
    {
      "epoch": 0.3263149716416751,
      "eval_loss": 1.2570444345474243,
      "eval_ppl": 3.515017256178416,
      "step": 2100
    },
    {
      "epoch": 0.3418537798150882,
      "grad_norm": 0.7734375,
      "learning_rate": 3.290598290598291e-05,
      "loss": 1.2475,
      "step": 2200
    },
    {
      "epoch": 0.3418537798150882,
      "eval_loss": 1.2558902502059937,
      "eval_ppl": 3.510962618651161,
      "step": 2200
    },
    {
      "epoch": 0.35739258798850126,
      "grad_norm": 0.8515625,
      "learning_rate": 3.212898212898213e-05,
      "loss": 1.2615,
      "step": 2300
    },
    {
      "epoch": 0.35739258798850126,
      "eval_loss": 1.2562856674194336,
      "eval_ppl": 3.512351188220382,
      "step": 2300
    },
    {
      "epoch": 0.3729313961619144,
      "grad_norm": 1.1015625,
      "learning_rate": 3.135198135198135e-05,
      "loss": 1.2366,
      "step": 2400
    },
    {
      "epoch": 0.3729313961619144,
      "eval_loss": 1.2552388906478882,
      "eval_ppl": 3.5086764642264483,
      "step": 2400
    },
    {
      "epoch": 0.3884702043353275,
      "grad_norm": 0.76953125,
      "learning_rate": 3.057498057498058e-05,
      "loss": 1.2663,
      "step": 2500
    },
    {
      "epoch": 0.3884702043353275,
      "eval_loss": 1.2561931610107422,
      "eval_ppl": 3.512026288253793,
      "step": 2500
    },
    {
      "epoch": 0.4040090125087406,
      "grad_norm": 0.7421875,
      "learning_rate": 2.9797979797979796e-05,
      "loss": 1.2727,
      "step": 2600
    },
    {
      "epoch": 0.4040090125087406,
      "eval_loss": 1.2543344497680664,
      "eval_ppl": 3.5055045084376006,
      "step": 2600
    },
    {
      "epoch": 0.4195478206821537,
      "grad_norm": 1.0703125,
      "learning_rate": 2.9020979020979022e-05,
      "loss": 1.2253,
      "step": 2700
    },
    {
      "epoch": 0.4195478206821537,
      "eval_loss": 1.255882978439331,
      "eval_ppl": 3.510937087843064,
      "step": 2700
    },
    {
      "epoch": 0.43508662885556676,
      "grad_norm": 1.296875,
      "learning_rate": 2.8243978243978248e-05,
      "loss": 1.2849,
      "step": 2800
    },
    {
      "epoch": 0.43508662885556676,
      "eval_loss": 1.2551040649414062,
      "eval_ppl": 3.5082034363322188,
      "step": 2800
    },
    {
      "epoch": 0.4506254370289799,
      "grad_norm": 0.8984375,
      "learning_rate": 2.7466977466977467e-05,
      "loss": 1.2461,
      "step": 2900
    },
    {
      "epoch": 0.4506254370289799,
      "eval_loss": 1.2549728155136108,
      "eval_ppl": 3.507743016854168,
      "step": 2900
    },
    {
      "epoch": 0.46616424520239297,
      "grad_norm": 3.5625,
      "learning_rate": 2.6689976689976692e-05,
      "loss": 1.2615,
      "step": 3000
    },
    {
      "epoch": 0.46616424520239297,
      "eval_loss": 1.2541313171386719,
      "eval_ppl": 3.5047924984081305,
      "step": 3000
    },
    {
      "epoch": 0.4817030533758061,
      "grad_norm": 1.59375,
      "learning_rate": 2.591297591297591e-05,
      "loss": 1.2752,
      "step": 3100
    },
    {
      "epoch": 0.4817030533758061,
      "eval_loss": 1.2538412809371948,
      "eval_ppl": 3.5037761291039975,
      "step": 3100
    },
    {
      "epoch": 0.4972418615492192,
      "grad_norm": 0.9375,
      "learning_rate": 2.5135975135975137e-05,
      "loss": 1.2733,
      "step": 3200
    },
    {
      "epoch": 0.4972418615492192,
      "eval_loss": 1.25331449508667,
      "eval_ppl": 3.501930875485199,
      "step": 3200
    },
    {
      "epoch": 0.5127806697226323,
      "grad_norm": 2.375,
      "learning_rate": 2.435897435897436e-05,
      "loss": 1.2415,
      "step": 3300
    },
    {
      "epoch": 0.5127806697226323,
      "eval_loss": 1.2540793418884277,
      "eval_ppl": 3.5046103406748594,
      "step": 3300
    },
    {
      "epoch": 0.5283194778960454,
      "grad_norm": 1.0546875,
      "learning_rate": 2.358197358197358e-05,
      "loss": 1.2516,
      "step": 3400
    },
    {
      "epoch": 0.5283194778960454,
      "eval_loss": 1.2535090446472168,
      "eval_ppl": 3.50261224087561,
      "step": 3400
    },
    {
      "epoch": 0.5438582860694585,
      "grad_norm": 1.1953125,
      "learning_rate": 2.2804972804972807e-05,
      "loss": 1.2653,
      "step": 3500
    },
    {
      "epoch": 0.5438582860694585,
      "eval_loss": 1.2529672384262085,
      "eval_ppl": 3.5007150177837723,
      "step": 3500
    },
    {
      "epoch": 0.5593970942428715,
      "grad_norm": 0.9765625,
      "learning_rate": 2.202797202797203e-05,
      "loss": 1.238,
      "step": 3600
    },
    {
      "epoch": 0.5593970942428715,
      "eval_loss": 1.2533191442489624,
      "eval_ppl": 3.5019471565680234,
      "step": 3600
    },
    {
      "epoch": 0.5749359024162847,
      "grad_norm": 0.875,
      "learning_rate": 2.1250971250971252e-05,
      "loss": 1.2588,
      "step": 3700
    },
    {
      "epoch": 0.5749359024162847,
      "eval_loss": 1.253620982170105,
      "eval_ppl": 3.5030043365581918,
      "step": 3700
    },
    {
      "epoch": 0.5904747105896978,
      "grad_norm": 1.3984375,
      "learning_rate": 2.0473970473970474e-05,
      "loss": 1.2717,
      "step": 3800
    },
    {
      "epoch": 0.5904747105896978,
      "eval_loss": 1.2537480592727661,
      "eval_ppl": 3.5034495164853796,
      "step": 3800
    },
    {
      "epoch": 0.6060135187631108,
      "grad_norm": 0.96484375,
      "learning_rate": 1.9696969696969697e-05,
      "loss": 1.2369,
      "step": 3900
    },
    {
      "epoch": 0.6060135187631108,
      "eval_loss": 1.2530107498168945,
      "eval_ppl": 3.5008673420764884,
      "step": 3900
    },
    {
      "epoch": 0.621552326936524,
      "grad_norm": 1.6484375,
      "learning_rate": 1.891996891996892e-05,
      "loss": 1.2503,
      "step": 4000
    },
    {
      "epoch": 0.621552326936524,
      "eval_loss": 1.253423810005188,
      "eval_ppl": 3.502313709697873,
      "step": 4000
    },
    {
      "epoch": 0.6370911351099371,
      "grad_norm": 0.65625,
      "learning_rate": 1.8142968142968145e-05,
      "loss": 1.2758,
      "step": 4100
    },
    {
      "epoch": 0.6370911351099371,
      "eval_loss": 1.2538177967071533,
      "eval_ppl": 3.5036938465855423,
      "step": 4100
    },
    {
      "epoch": 0.6526299432833502,
      "grad_norm": 1.5625,
      "learning_rate": 1.7365967365967367e-05,
      "loss": 1.2305,
      "step": 4200
    },
    {
      "epoch": 0.6526299432833502,
      "eval_loss": 1.2532309293746948,
      "eval_ppl": 3.5016382463653524,
      "step": 4200
    },
    {
      "epoch": 0.6681687514567632,
      "grad_norm": 1.1640625,
      "learning_rate": 1.658896658896659e-05,
      "loss": 1.2734,
      "step": 4300
    },
    {
      "epoch": 0.6681687514567632,
      "eval_loss": 1.2532403469085693,
      "eval_ppl": 3.5016712233174343,
      "step": 4300
    },
    {
      "epoch": 0.6837075596301764,
      "grad_norm": 1.265625,
      "learning_rate": 1.581196581196581e-05,
      "loss": 1.2429,
      "step": 4400
    },
    {
      "epoch": 0.6837075596301764,
      "eval_loss": 1.2531423568725586,
      "eval_ppl": 3.501328111239221,
      "step": 4400
    },
    {
      "epoch": 0.6992463678035895,
      "grad_norm": 1.0390625,
      "learning_rate": 1.5034965034965034e-05,
      "loss": 1.242,
      "step": 4500
    },
    {
      "epoch": 0.6992463678035895,
      "eval_loss": 1.2526891231536865,
      "eval_ppl": 3.4997415508468652,
      "step": 4500
    },
    {
      "epoch": 0.7147851759770025,
      "grad_norm": 0.97265625,
      "learning_rate": 1.425796425796426e-05,
      "loss": 1.2631,
      "step": 4600
    },
    {
      "epoch": 0.7147851759770025,
      "eval_loss": 1.252690076828003,
      "eval_ppl": 3.499744888462088,
      "step": 4600
    },
    {
      "epoch": 0.7303239841504157,
      "grad_norm": 1.3828125,
      "learning_rate": 1.3480963480963482e-05,
      "loss": 1.2434,
      "step": 4700
    },
    {
      "epoch": 0.7303239841504157,
      "eval_loss": 1.252888798713684,
      "eval_ppl": 3.5004404334734454,
      "step": 4700
    },
    {
      "epoch": 0.7458627923238288,
      "grad_norm": 1.5703125,
      "learning_rate": 1.2703962703962704e-05,
      "loss": 1.2345,
      "step": 4800
    },
    {
      "epoch": 0.7458627923238288,
      "eval_loss": 1.2531585693359375,
      "eval_ppl": 3.5013848768531557,
      "step": 4800
    },
    {
      "epoch": 0.7614016004972418,
      "grad_norm": 0.91015625,
      "learning_rate": 1.1926961926961927e-05,
      "loss": 1.2702,
      "step": 4900
    },
    {
      "epoch": 0.7614016004972418,
      "eval_loss": 1.252984881401062,
      "eval_ppl": 3.500776781355645,
      "step": 4900
    },
    {
      "epoch": 0.776940408670655,
      "grad_norm": 0.65234375,
      "learning_rate": 1.114996114996115e-05,
      "loss": 1.2521,
      "step": 5000
    },
    {
      "epoch": 0.776940408670655,
      "eval_loss": 1.2527656555175781,
      "eval_ppl": 3.5000094045903705,
      "step": 5000
    },
    {
      "epoch": 0.7924792168440681,
      "grad_norm": 1.140625,
      "learning_rate": 1.0372960372960373e-05,
      "loss": 1.2106,
      "step": 5100
    },
    {
      "epoch": 0.7924792168440681,
      "eval_loss": 1.2528257369995117,
      "eval_ppl": 3.500219696659446,
      "step": 5100
    },
    {
      "epoch": 0.8080180250174812,
      "grad_norm": 0.95703125,
      "learning_rate": 9.595959595959595e-06,
      "loss": 1.2712,
      "step": 5200
    },
    {
      "epoch": 0.8080180250174812,
      "eval_loss": 1.2528235912322998,
      "eval_ppl": 3.500212186010845,
      "step": 5200
    },
    {
      "epoch": 0.8235568331908942,
      "grad_norm": 1.0625,
      "learning_rate": 8.81895881895882e-06,
      "loss": 1.2609,
      "step": 5300
    },
    {
      "epoch": 0.8235568331908942,
      "eval_loss": 1.2529559135437012,
      "eval_ppl": 3.5006753728219917,
      "step": 5300
    },
    {
      "epoch": 0.8390956413643074,
      "grad_norm": 1.9609375,
      "learning_rate": 8.041958041958042e-06,
      "loss": 1.2435,
      "step": 5400
    },
    {
      "epoch": 0.8390956413643074,
      "eval_loss": 1.2528831958770752,
      "eval_ppl": 3.50042082113258,
      "step": 5400
    },
    {
      "epoch": 0.8546344495377205,
      "grad_norm": 1.203125,
      "learning_rate": 7.264957264957266e-06,
      "loss": 1.2609,
      "step": 5500
    },
    {
      "epoch": 0.8546344495377205,
      "eval_loss": 1.2527810335159302,
      "eval_ppl": 3.5000632281430746,
      "step": 5500
    },
    {
      "epoch": 0.8701732577111335,
      "grad_norm": 0.71875,
      "learning_rate": 6.487956487956488e-06,
      "loss": 1.2905,
      "step": 5600
    },
    {
      "epoch": 0.8701732577111335,
      "eval_loss": 1.2527929544448853,
      "eval_ppl": 3.500104952396851,
      "step": 5600
    },
    {
      "epoch": 0.8857120658845467,
      "grad_norm": 0.97265625,
      "learning_rate": 5.710955710955711e-06,
      "loss": 1.2444,
      "step": 5700
    },
    {
      "epoch": 0.8857120658845467,
      "eval_loss": 1.2529510259628296,
      "eval_ppl": 3.500658263029815,
      "step": 5700
    },
    {
      "epoch": 0.9012508740579598,
      "grad_norm": 0.9140625,
      "learning_rate": 4.9339549339549335e-06,
      "loss": 1.2467,
      "step": 5800
    },
    {
      "epoch": 0.9012508740579598,
      "eval_loss": 1.2528800964355469,
      "eval_ppl": 3.5004099717997335,
      "step": 5800
    },
    {
      "epoch": 0.9167896822313728,
      "grad_norm": 4.3125,
      "learning_rate": 4.156954156954157e-06,
      "loss": 1.2568,
      "step": 5900
    },
    {
      "epoch": 0.9167896822313728,
      "eval_loss": 1.2527586221694946,
      "eval_ppl": 3.4999847878925014,
      "step": 5900
    },
    {
      "epoch": 0.9323284904047859,
      "grad_norm": 1.4296875,
      "learning_rate": 3.3799533799533803e-06,
      "loss": 1.2457,
      "step": 6000
    },
    {
      "epoch": 0.9323284904047859,
      "eval_loss": 1.25282621383667,
      "eval_ppl": 3.5002213656946575,
      "step": 6000
    }
  ],
  "logging_steps": 100,
  "max_steps": 6435,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.922508342571827e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
